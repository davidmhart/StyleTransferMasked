{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa2e305",
   "metadata": {},
   "source": [
    "### Make stylizers, metric functions, and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cd7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SAM\n",
    "import os\n",
    "from styleTransfer import StyleTransferLinear, StyleTransferPartialConv\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stylizer_ref = StyleTransferLinear(device=\"cuda\")\n",
    "stylizer = StyleTransferPartialConv(device=\"cuda\")\n",
    "\n",
    "sam_data_dir = \"../SA-1B-Dataset/\"\n",
    "style_dir = \"styles/\"\n",
    "\n",
    "sam_files = os.listdir(sam_data_dir)\n",
    "sam_jsons = [f for f in sam_files if f.endswith(\".json\")]\n",
    "#sam_jsons.sort()\n",
    "sam_images = [f for f in sam_files if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "#sam_images.sort()\n",
    "\n",
    "style_ims = os.listdir(style_dir)\n",
    "                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf43903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "\n",
    "def computeAllMetrics(content, style, mask, result_stm, result_pc):\n",
    "\n",
    "    # Between content and masked region\n",
    "    content_np = utils.tensorToImage(content)\n",
    "    mask_np = utils.tensorToMask(mask)\n",
    "    gray_range = metrics.computeColorRange(content_np, in_gray=True)\n",
    "    gray_range_masked = metrics.computeColorRange(content_np, mask_np, in_gray=True)\n",
    "    gray_average = metrics.computeColorAverage(content_np, in_gray=True)\n",
    "    gray_average_masked = metrics.computeColorAverage(content_np, mask_np, in_gray=True)\n",
    "    gray_std = metrics.computeColorSTD(content_np, in_gray=True)\n",
    "    gray_std_masked = metrics.computeColorSTD(content_np, mask_np, in_gray=True)\n",
    "    gray_skew = metrics.computeColorSkewness(content_np, in_gray=True)\n",
    "    gray_skew_masked = metrics.computeColorSkewness(content_np, mask_np, in_gray=True)\n",
    "    gray_kurt = metrics.computeColorKurtosis(content_np, in_gray=True)\n",
    "    gray_kurt_masked = metrics.computeColorKurtosis(content_np, mask_np, in_gray=True)\n",
    "    gray_emd = metrics.computeEarthMoversDistance(content_np, content_np, None, mask_np, in_gray=True)\n",
    "    color_sliced_emd = metrics.computeSlicedWassersteinDistance(content_np, content_np, None, mask_np)\n",
    "\n",
    "    style_np = utils.tensorToImage(style)\n",
    "    result_stm_np = utils.tensorToImage(result_stm)\n",
    "    result_pc_np = utils.tensorToImage(result_pc)\n",
    "\n",
    "    # Between style, style-then-mask, and partial conv\n",
    "    gray_range_style = metrics.computeColorRange(style_np, in_gray=True)\n",
    "    gray_range_result_stm = metrics.computeColorRange(result_stm_np, mask_np, in_gray=True)\n",
    "    gray_range_result_pc = metrics.computeColorRange(result_pc_np, mask_np, in_gray=True)\n",
    "\n",
    "    gray_average_style = metrics.computeColorAverage(style_np, in_gray=True)\n",
    "    gray_average_result_stm = metrics.computeColorAverage(result_stm_np, mask_np, in_gray=True)\n",
    "    gray_average_result_pc = metrics.computeColorAverage(result_pc_np, mask_np, in_gray=True)\n",
    "\n",
    "    gray_std_style = metrics.computeColorSTD(style_np, in_gray=True)\n",
    "    gray_std_result_stm = metrics.computeColorSTD(result_stm_np, mask_np, in_gray=True)\n",
    "    gray_std_result_pc = metrics.computeColorSTD(result_pc_np, mask_np, in_gray=True)\n",
    "\n",
    "    gray_emd_result_stm = metrics.computeEarthMoversDistance(style_np, result_stm_np, None, mask_np, in_gray=True)\n",
    "    gray_emd_result_pc = metrics.computeEarthMoversDistance(style_np, result_pc_np, None, mask_np, in_gray=True)\n",
    "\n",
    "    color_sliced_emd_result_stm = metrics.computeSlicedWassersteinDistance(style_np, result_stm_np, None, mask_np)\n",
    "    color_sliced_emd_result_pc = metrics.computeSlicedWassersteinDistance(style_np, result_pc_np, None, mask_np)\n",
    "\n",
    "    result_metrics = {\n",
    "        \"gray_range\": gray_range,\n",
    "        \"gray_range_masked\": gray_range_masked,\n",
    "        \"gray_average\": gray_average,\n",
    "        \"gray_average_masked\": gray_average_masked,\n",
    "        \"gray_std\": gray_std,\n",
    "        \"gray_std_masked\": gray_std_masked,\n",
    "        \"gray_skew\": gray_skew,\n",
    "        \"gray_skew_masked\": gray_skew_masked,\n",
    "        \"gray_kurt\": gray_kurt,\n",
    "        \"gray_kurt_masked\": gray_kurt_masked,\n",
    "        \"gray_emd\": gray_emd,\n",
    "        \"color_sliced_emd\": color_sliced_emd,\n",
    "\n",
    "        \"gray_range_style\": gray_range_style,\n",
    "        \"gray_range_result_stm\": gray_range_result_stm,\n",
    "        \"gray_range_result_pc\": gray_range_result_pc,\n",
    "\n",
    "        \"gray_average_style\": gray_average_style,\n",
    "        \"gray_average_result_stm\": gray_average_result_stm,\n",
    "        \"gray_average_result_pc\": gray_average_result_pc,\n",
    "\n",
    "        \"gray_std_style\": gray_std_style,\n",
    "        \"gray_std_result_stm\": gray_std_result_stm,\n",
    "        \"gray_std_result_pc\": gray_std_result_pc,\n",
    "\n",
    "        \"gray_emd_result_stm\": gray_emd_result_stm,\n",
    "        \"gray_emd_result_pc\": gray_emd_result_pc,\n",
    "\n",
    "        \"color_sliced_emd_result_stm\": color_sliced_emd_result_stm,\n",
    "        \"color_sliced_emd_result_pc\": color_sliced_emd_result_pc\n",
    "    }\n",
    "\n",
    "    return result_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47d5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"content\", \"style\", \"mask_num\", \"mask_area\", \"mask_ratio\",\n",
    "                            \"gray_range\", \"gray_range_masked\",\n",
    "                            \"gray_average\", \"gray_average_masked\",\n",
    "                            \"gray_std\", \"gray_std_masked\",\n",
    "                            \"gray_skew\", \"gray_skew_masked\",\n",
    "                            \"gray_kurt\", \"gray_kurt_masked\",\n",
    "                            \"gray_emd\", \"color_sliced_emd\",\n",
    "    \n",
    "                            \"gray_range_style\", \"gray_range_result_stm\", \"gray_range_result_pc\",\n",
    "                            \"gray_average_style\", \"gray_average_result_stm\", \"gray_average_result_pc\",\n",
    "                            \"gray_std_style\", \"gray_std_result_stm\", \"gray_std_result_pc\",\n",
    "                            \"gray_emd_result_stm\", \"gray_emd_result_pc\",\n",
    "                            \"color_sliced_emd_result_stm\", \"color_sliced_emd_result_pc\",\n",
    "                            \n",
    "                            \"style_loss_stm\", \"style_loss_pc\",\n",
    "                            ])\n",
    "\n",
    "vgg_model = metrics.getVGGmodel(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab9bd2",
   "metadata": {},
   "source": [
    "### Stylize each image and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d7500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [1:08:38<00:00, 54.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         content         style mask_num mask_area  mask_ratio  gray_range  \\\n",
      "0      sa_1.json   style-2.jpg       52     94493    0.030580    0.999900   \n",
      "1      sa_2.json   style-1.jpg       63    359568    0.106539    0.911315   \n",
      "2      sa_3.json  style-10.jpg       85   1313042    0.389222    0.999900   \n",
      "3      sa_4.json   style-1.jpg       81    171529    0.050823    0.933476   \n",
      "4      sa_5.json   style-6.jpg        8   2297012    0.680596    0.976838   \n",
      "..           ...           ...      ...       ...         ...         ...   \n",
      "495  sa_496.json   style-8.jpg       80    393465    0.116582    0.999900   \n",
      "496  sa_497.json   style-6.jpg       81    363704    0.107764    0.999900   \n",
      "497  sa_498.json   style-0.jpg       89      7355    0.002179    0.999900   \n",
      "498  sa_499.json   style-9.jpg       49    201230    0.059624    0.999900   \n",
      "499  sa_500.json   style-4.jpg       51    136218    0.040361    0.999006   \n",
      "\n",
      "     gray_range_masked  gray_average  gray_average_masked  gray_std  ...  \\\n",
      "0             0.944206      0.551953             0.332182  0.219440  ...   \n",
      "1             0.690858      0.538590             0.467107  0.145547  ...   \n",
      "2             0.616755      0.620700             0.826457  0.250635  ...   \n",
      "3             0.689015      0.566704             0.571168  0.276694  ...   \n",
      "4             0.976838      0.437256             0.267786  0.331783  ...   \n",
      "..                 ...           ...                  ...       ...  ...   \n",
      "495           0.998728      0.399351             0.366373  0.198605  ...   \n",
      "496           0.686526      0.342371             0.052690  0.327424  ...   \n",
      "497           0.911112      0.439164             0.349454  0.243054  ...   \n",
      "498           0.916182      0.428774             0.307206  0.242183  ...   \n",
      "499           0.922293      0.605647             0.584951  0.168659  ...   \n",
      "\n",
      "     gray_average_result_pc  gray_std_style  gray_std_result_stm  \\\n",
      "0                  0.692248        0.158041             0.168916   \n",
      "1                  0.918518        0.213468             0.196214   \n",
      "2                  0.671450        0.279354             0.022423   \n",
      "3                  0.971514        0.213468             0.067146   \n",
      "4                  0.430374        0.276174             0.213268   \n",
      "..                      ...             ...                  ...   \n",
      "495                0.328728        0.219593             0.212034   \n",
      "496                0.312510        0.276174             0.093919   \n",
      "497                0.283620        0.269274             0.225846   \n",
      "498                0.230445        0.139015             0.131557   \n",
      "499                0.705024        0.230819             0.273194   \n",
      "\n",
      "     gray_std_result_pc  gray_emd_result_stm  gray_emd_result_pc  \\\n",
      "0              0.141162             0.074462            0.041901   \n",
      "1              0.162869             0.206131            0.046372   \n",
      "2              0.116519             0.222556            0.137351   \n",
      "3              0.114597             0.063418            0.047353   \n",
      "4              0.249991             0.092463            0.034025   \n",
      "..                  ...                  ...                 ...   \n",
      "495            0.224208             0.029670            0.028923   \n",
      "496            0.135200             0.208167            0.143317   \n",
      "497            0.258834             0.060827            0.109550   \n",
      "498            0.131385             0.040311            0.014315   \n",
      "499            0.270065             0.084982            0.080947   \n",
      "\n",
      "     color_sliced_emd_result_stm  color_sliced_emd_result_pc  style_loss_stm  \\\n",
      "0                       0.104395                    0.119398     1094.935913   \n",
      "1                       0.262468                    0.076619      911.430847   \n",
      "2                       0.344554                    0.198712      494.338623   \n",
      "3                       0.170297                    0.147495       64.902817   \n",
      "4                       0.111988                    0.044499      591.556885   \n",
      "..                           ...                         ...             ...   \n",
      "495                     0.058247                    0.055092      353.294067   \n",
      "496                     0.293612                    0.158627      841.244873   \n",
      "497                     0.089345                    0.156022     1135.099609   \n",
      "498                     0.065761                    0.036519      608.185730   \n",
      "499                     0.117157                    0.104801      450.286407   \n",
      "\n",
      "     style_loss_pc  \n",
      "0       703.634583  \n",
      "1       213.295502  \n",
      "2       184.911163  \n",
      "3        57.094086  \n",
      "4       604.036377  \n",
      "..             ...  \n",
      "495     294.695648  \n",
      "496     699.514771  \n",
      "497    1208.626099  \n",
      "498     134.409927  \n",
      "499     330.501404  \n",
      "\n",
      "[500 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "num_iters = 500\n",
    "for i in trange(1,num_iters+1):\n",
    "    #sam_json_fn = sam_jsons[i]\n",
    "    sam_json_fn = \"sa_\" + str(i) + \".json\"\n",
    "    if not sam_json_fn in sam_jsons:\n",
    "        print(\"Skipping\", sam_json_fn, \"as it does not exist in the dataset.\")\n",
    "        continue\n",
    "\n",
    "    sam_json_path = os.path.join(sam_data_dir, sam_json_fn)\n",
    "    sam_image_path = os.path.join(sam_data_dir, sam_json_fn.replace(\".json\", \".jpg\"))\n",
    "    \n",
    "    if not os.path.exists(sam_image_path):\n",
    "        continue\n",
    "    \n",
    "    # choose a random mask and style\n",
    "    sam_json = SAM.loadMaskJSON(sam_json_path)\n",
    "    #print(len(sam_json['annotations']), \"masks found in\", sam_json_fn)\n",
    "    num_masks = min(len(sam_json['annotations']),100)  # Limit to 100 masks for performance\n",
    "\n",
    "    # Print mask areas in order\n",
    "    #for mask_num in range(num_masks):\n",
    "    #    mask_area = sam_json['annotations'][mask_num]['area']\n",
    "    #    print(f\"Mask {mask_num}: Area = {mask_area}\")\n",
    "\n",
    "    # Attempt to find a mask with a sufficient area\n",
    "    image_width = sam_json['image']['width']\n",
    "    image_height = sam_json['image']['height']\n",
    "    total_pixels = image_width * image_height\n",
    "\n",
    "    # Random order of numbers from 0 to num_masks-1\n",
    "    mask_indices = np.arange(num_masks,dtype=np.int32)\n",
    "    np.random.shuffle(mask_indices)\n",
    "\n",
    "    for index in mask_indices:\n",
    "        mask_num = int(index)\n",
    "        mask_area = sam_json['annotations'][mask_num]['area']\n",
    "        mask_ratio = mask_area / total_pixels\n",
    "        if mask_ratio < 0.02: # Only consider masks that cover more than 2% of the image\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    mask = SAM.loadIndices(sam_json, mask_num)[0]\n",
    "\n",
    "    content_im = utils.loadImage(sam_image_path)\n",
    "\n",
    "    style_im_choice = np.random.choice(style_ims)\n",
    "    style_im_path = os.path.join(style_dir, style_im_choice)\n",
    "    style_im = utils.loadImage(style_im_path)\n",
    "        \n",
    "    result_stm = stylizer_ref(content_im, style_im, mask)\n",
    "    result_pc = stylizer(content_im, style_im, mask)\n",
    "\n",
    "    result_metrics = computeAllMetrics(content_im, style_im, mask, result_stm, result_pc)\n",
    "\n",
    "    style_loss_stm = metrics.computePerceptualStyleLoss(result_stm, style_im, mask, vgg_model)\n",
    "    style_loss_pc = metrics.computePerceptualStyleLoss(result_pc, style_im, mask, vgg_model)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({\n",
    "        \"content\": sam_json_fn,\n",
    "        \"style\": style_im_choice,\n",
    "        \"mask_num\": mask_num,\n",
    "        \"mask_area\": mask_area,\n",
    "        \"mask_ratio\": mask_ratio,\n",
    "        \"gray_range\": result_metrics[\"gray_range\"],\n",
    "        \"gray_range_masked\": result_metrics[\"gray_range_masked\"],\n",
    "        \"gray_average\": result_metrics[\"gray_average\"],\n",
    "        \"gray_average_masked\": result_metrics[\"gray_average_masked\"],\n",
    "        \"gray_std\": result_metrics[\"gray_std\"],\n",
    "        \"gray_std_masked\": result_metrics[\"gray_std_masked\"],\n",
    "        \"gray_skew\": result_metrics[\"gray_skew\"],\n",
    "        \"gray_skew_masked\": result_metrics[\"gray_skew_masked\"],\n",
    "        \"gray_kurt\": result_metrics[\"gray_kurt\"],\n",
    "        \"gray_kurt_masked\": result_metrics[\"gray_kurt_masked\"],\n",
    "        \"gray_emd\": result_metrics[\"gray_emd\"],\n",
    "        \"color_sliced_emd\": result_metrics[\"color_sliced_emd\"],\n",
    "        \"gray_range_style\": result_metrics[\"gray_range_style\"],\n",
    "        \"gray_range_result_stm\": result_metrics[\"gray_range_result_stm\"],\n",
    "        \"gray_range_result_pc\": result_metrics[\"gray_range_result_pc\"],\n",
    "        \"gray_average_style\": result_metrics[\"gray_average_style\"],\n",
    "        \"gray_average_result_stm\": result_metrics[\"gray_average_result_stm\"],\n",
    "        \"gray_average_result_pc\": result_metrics[\"gray_average_result_pc\"],\n",
    "        \"gray_std_style\": result_metrics[\"gray_std_style\"],\n",
    "        \"gray_std_result_stm\": result_metrics[\"gray_std_result_stm\"],\n",
    "        \"gray_std_result_pc\": result_metrics[\"gray_std_result_pc\"],\n",
    "        \"gray_emd_result_stm\": result_metrics[\"gray_emd_result_stm\"],\n",
    "        \"gray_emd_result_pc\": result_metrics[\"gray_emd_result_pc\"],\n",
    "        \"color_sliced_emd_result_stm\": result_metrics[\"color_sliced_emd_result_stm\"],\n",
    "        \"color_sliced_emd_result_pc\": result_metrics[\"color_sliced_emd_result_pc\"],\n",
    "        \"style_loss_stm\": style_loss_stm,\n",
    "        \"style_loss_pc\": style_loss_pc\n",
    "        \n",
    "    })], ignore_index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dabff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"outputs/style_transfer_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6dff6",
   "metadata": {},
   "source": [
    "### Generate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beaf60bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Grayscale EMD (STM): 0.12213961797303154\n",
      "Average Grayscale EMD (PC): 0.0855057935550118\n",
      "Average Color Sliced EMD (STM): 0.16830194202697885\n",
      "Average Color Sliced EMD (PC): 0.11813415935531874\n",
      "Average Style Loss (STM): 760.131100692749\n",
      "Average Style Loss (PC): 449.24159561920163\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Grayscale EMD (STM):\", df[\"gray_emd_result_stm\"].mean())\n",
    "print(\"Average Grayscale EMD (PC):\", df[\"gray_emd_result_pc\"].mean())\n",
    "print(\"Average Color Sliced EMD (STM):\", df[\"color_sliced_emd_result_stm\"].mean())\n",
    "print(\"Average Color Sliced EMD (PC):\", df[\"color_sliced_emd_result_pc\"].mean())\n",
    "print(\"Average Style Loss (STM):\", df[\"style_loss_stm\"].mean())\n",
    "print(\"Average Style Loss (PC):\", df[\"style_loss_pc\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc2a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
